<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>VerifAIble</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', 'Helvetica Neue', Arial, sans-serif;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 0;
            overflow: hidden;
            position: relative;
        }

        /* ËÉåÊôØÂõæÁâáÈ´òÊñØÊ®°Á≥ä */
        body::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: linear-gradient(135deg, #34d399 0%, #059669 100%);
            background-size: cover;
            background-position: center;
            filter: blur(80px);
            transform: scale(1.1);
            z-index: -2;
        }

        body::after {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.4);
            z-index: -1;
        }

        /* ÈÄöËØùÂ±èÂπï */
        .call-screen {
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: space-between;
            padding: 80px 40px 60px;
        }

        /* Â§¥ÂÉèÂå∫Âüü */
        .avatar-section {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }

        .avatar {
            width: 180px;
            height: 180px;
            border-radius: 50%;
            background: linear-gradient(135deg, #34d399 0%, #059669 100%);
            background-size: cover;
            background-position: center;
            margin-bottom: 30px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
            border: 4px solid rgba(255, 255, 255, 0.2);
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .avatar.pulse {
            animation: avatarPulse 2s infinite;
        }

        @keyframes avatarPulse {
            0%, 100% {
                transform: scale(1);
                box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
            }
            50% {
                transform: scale(1.05);
                box-shadow: 0 20px 80px rgba(52, 211, 153, 0.8);
            }
        }

        .caller-name {
            font-size: 42px;
            font-weight: 200;
            color: #ffffff;
            margin-bottom: 16px;
            letter-spacing: 1px;
            text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        .call-status {
            font-size: 18px;
            color: rgba(255, 255, 255, 0.7);
            font-weight: 300;
            letter-spacing: 0.5px;
            text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        /* ÊéßÂà∂ÊåâÈíÆÂå∫Âüü */
        .controls {
            display: flex;
            justify-content: center;
            gap: 80px;
            padding: 20px 0;
        }

        .control-btn {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s;
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.4);
            position: relative;
        }

        .control-btn::before {
            content: '';
            position: absolute;
            width: 100%;
            height: 100%;
            border-radius: 50%;
            background: inherit;
            filter: blur(20px);
            opacity: 0.6;
            z-index: -1;
        }

        .control-btn:active {
            transform: scale(0.95);
        }

        .control-btn:disabled {
            opacity: 0.4;
            cursor: not-allowed;
        }

        .btn-call {
            background: #34c759;
            font-size: 36px;
        }

        .btn-call:hover:not(:disabled) {
            background: #30b350;
            transform: scale(1.05);
        }

        .btn-end {
            background: #ff3b30;
            font-size: 36px;
        }

        .btn-end:hover:not(:disabled) {
            background: #e6342a;
            transform: scale(1.05);
        }

        /* ÂØπËØùËÆ∞ÂΩïÈöêËóè */
        .transcript {
            display: none;
        }

        /* Â£∞Á∫πÊ≥®ÂÜåÊ®°ÊÄÅÊ°Ü */
        .voiceprint-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.7);
            z-index: 1000;
            justify-content: center;
            align-items: center;
        }

        .voiceprint-modal.show {
            display: flex;
        }

        .voiceprint-content {
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(20px);
            border-radius: 30px;
            padding: 50px 40px;
            max-width: 500px;
            width: 90%;
            border: 1px solid rgba(255, 255, 255, 0.2);
            text-align: center;
        }

        .voiceprint-content h2 {
            font-size: 28px;
            font-weight: 300;
            color: #ffffff;
            margin-bottom: 20px;
            text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        .voiceprint-content p {
            font-size: 16px;
            color: rgba(255, 255, 255, 0.8);
            margin-bottom: 30px;
            line-height: 1.6;
        }

        .enrollment-text {
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            font-size: 18px;
            color: white;
            line-height: 1.8;
        }

        .recording-indicator {
            display: none;
            margin: 20px 0;
        }

        .recording-indicator.active {
            display: block;
        }

        .pulse-ring {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            background: rgba(255, 59, 48, 0.3);
            margin: 0 auto;
            position: relative;
            animation: pulseRing 1.5s infinite;
        }

        .pulse-ring::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: #ff3b30;
        }

        @keyframes pulseRing {
            0%, 100% {
                transform: scale(1);
                opacity: 1;
            }
            50% {
                transform: scale(1.2);
                opacity: 0.7;
            }
        }

        .voiceprint-btns {
            display: flex;
            gap: 15px;
            margin-top: 30px;
        }

        .voiceprint-btns button {
            flex: 1;
            padding: 18px 30px;
            background: white;
            color: #333;
            border: none;
            border-radius: 50px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.3);
        }

        .voiceprint-btns button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 12px 32px rgba(0, 0, 0, 0.4);
        }

        .voiceprint-btns button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .voiceprint-btns .btn-secondary {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border: 1px solid rgba(255, 255, 255, 0.3);
        }

        .voiceprint-status {
            margin-top: 15px;
            font-size: 14px;
            color: rgba(255, 255, 255, 0.7);
        }

        /* Voiceprint indicator (top right corner) */
        .voiceprint-indicator {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(20px);
            border-radius: 20px;
            padding: 10px 20px;
            border: 1px solid rgba(255, 255, 255, 0.2);
            display: flex;
            align-items: center;
            gap: 10px;
            z-index: 100;
            cursor: pointer;
            transition: all 0.3s;
        }

        .voiceprint-indicator:hover {
            background: rgba(255, 255, 255, 0.25);
        }

        .voiceprint-indicator .status-icon {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #34d399;
        }

        .voiceprint-indicator .status-icon.disabled {
            background: #6b7280;
        }

        .voiceprint-indicator .status-text {
            font-size: 14px;
            color: white;
            font-weight: 500;
        }

        /* ÈÄöËØùÊ®°ÂºèÈÄâÊã©Ê®°ÊÄÅÊ°Ü */
        .mode-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.7);
            z-index: 2000;
            justify-content: center;
            align-items: center;
        }

        .mode-modal.show {
            display: flex;
        }

        .mode-content {
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(20px);
            border-radius: 30px;
            padding: 40px 35px;
            max-width: 450px;
            width: 90%;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .mode-content h2 {
            font-size: 24px;
            font-weight: 300;
            color: #ffffff;
            margin-bottom: 25px;
            text-align: center;
            text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        .mode-option {
            background: rgba(255, 255, 255, 0.1);
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 15px;
            cursor: pointer;
            transition: all 0.3s;
        }

        .mode-option:hover {
            background: rgba(255, 255, 255, 0.2);
            border-color: rgba(255, 255, 255, 0.5);
            transform: translateY(-2px);
        }

        .mode-option.selected {
            background: rgba(52, 211, 153, 0.3);
            border-color: #34d399;
        }

        .mode-option-header {
            display: flex;
            align-items: center;
            gap: 12px;
            margin-bottom: 10px;
        }

        .mode-icon {
            font-size: 28px;
        }

        .mode-title {
            font-size: 18px;
            font-weight: 600;
            color: white;
        }

        .mode-badge {
            background: #34d399;
            color: white;
            font-size: 11px;
            padding: 3px 8px;
            border-radius: 10px;
            font-weight: 600;
            margin-left: auto;
        }

        .mode-description {
            font-size: 14px;
            color: rgba(255, 255, 255, 0.8);
            line-height: 1.5;
            margin-left: 40px;
        }

        .voiceprint-option {
            margin-top: 12px;
            margin-left: 40px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .voiceprint-option input[type="checkbox"] {
            width: 20px;
            height: 20px;
            cursor: pointer;
        }

        .voiceprint-option label {
            font-size: 14px;
            color: white;
            cursor: pointer;
            user-select: none;
        }

        .mode-warning {
            background: rgba(245, 158, 11, 0.2);
            border: 1px solid rgba(245, 158, 11, 0.4);
            border-radius: 10px;
            padding: 12px;
            margin-top: 20px;
            font-size: 13px;
            color: rgba(255, 255, 255, 0.9);
            line-height: 1.5;
        }

        .mode-warning-icon {
            display: inline-block;
            margin-right: 5px;
        }

        .mode-buttons {
            display: flex;
            gap: 10px;
            margin-top: 25px;
        }

        .mode-buttons button {
            flex: 1;
            padding: 15px;
            background: white;
            color: #333;
            border: none;
            border-radius: 50px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .mode-buttons button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);
        }

        .mode-buttons button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }
    </style>
</head>
<body>
    <!-- Voiceprint status indicator -->
    <div class="voiceprint-indicator" id="voiceprintIndicator" onclick="openSettings()" title="Click to change settings">
        <div class="status-icon" id="voiceprintIcon"></div>
        <div class="status-text" id="voiceprintText">Mode</div>
    </div>

    <!-- ÈÄöËØùÂ±èÂπï -->
    <div class="call-screen">
        <!-- Â§¥ÂÉèÂå∫Âüü -->
        <div class="avatar-section">
            <div id="avatar" class="avatar">
                <span style="font-size: 52px; font-weight: 300; color: white; text-shadow: 0 2px 8px rgba(0,0,0,0.3);">VAI</span>
            </div>
            <div class="caller-name">VerifAIble</div>
            <div id="callStatus" class="call-status">Click to start conversation</div>
        </div>

        <!-- ÂØπËØùËÆ∞ÂΩïÔºàÈöêËóèÔºå‰ªÖÁî®‰∫é‰øùÂ≠òÂéÜÂè≤Ôºâ -->
        <div class="transcript" id="transcript"></div>

        <!-- ÊéßÂà∂ÊåâÈíÆ -->
        <div class="controls">
            <button id="connectBtn" class="control-btn btn-call">
                ‚òé
            </button>
            <button id="disconnectBtn" class="control-btn btn-end" disabled>
                ‚úï
            </button>
        </div>
    </div>

    <audio id="audioElement" autoplay></audio>

    <!-- ÈÄöËØùÊ®°ÂºèÈÄâÊã©Ê®°ÊÄÅÊ°Ü -->
    <div id="modeModal" class="mode-modal">
        <div class="mode-content">
            <h2>üìû Select Call Mode</h2>

            <!-- Âê¨Á≠íÊ®°Âºè -->
            <div class="mode-option" id="earpieceMode" onclick="selectMode('earpiece')">
                <div class="mode-option-header">
                    <span class="mode-icon">üì±</span>
                    <span class="mode-title">Earpiece Mode</span>
                    <span class="mode-badge">Recommended</span>
                </div>
                <div class="mode-description">
                    Hold phone close to ear, like a regular call<br>
                    ‚úì More private<br>
                    ‚úì Auto noise filtering<br>
                    ‚úì No voiceprint needed
                </div>
            </div>

            <!-- ÂÖçÊèêÊ®°Âºè -->
            <div class="mode-option" id="speakerMode" onclick="selectMode('speaker')">
                <div class="mode-option-header">
                    <span class="mode-icon">üîä</span>
                    <span class="mode-title">Speaker Mode</span>
                </div>
                <div class="mode-description">
                    Hands-free, suitable for open environments
                </div>
                <div class="voiceprint-option">
                    <input type="checkbox" id="enableVoiceprintCheck" onclick="event.stopPropagation()">
                    <label for="enableVoiceprintCheck" onclick="event.stopPropagation()">
                        Enable voiceprint verification (filter other voices)
                    </label>
                </div>
            </div>

            <div class="mode-warning" id="modeWarning" style="display: none;">
                <span class="mode-warning-icon">‚ö†Ô∏è</span>
                <strong>Note:</strong> Speaker mode without voiceprint may pick up other voices,
                which could confuse the AI. Consider enabling voiceprint for better experience.
            </div>

            <div class="mode-buttons">
                <button onclick="confirmMode()">Confirm</button>
            </div>
        </div>
    </div>

    <!-- Â£∞Á∫πÊ≥®ÂÜåÊ®°ÊÄÅÊ°Ü -->
    <div id="voiceprintModal" class="voiceprint-modal">
        <div class="voiceprint-content">
            <h2>Voice Registration</h2>
            <p>To enable voice verification, please read the following text clearly:</p>

            <div class="enrollment-text" id="enrollmentText"></div>

            <div class="recording-indicator" id="recordingIndicator">
                <div class="pulse-ring"></div>
                <p style="margin-top: 15px; color: white;">Recording...</p>
            </div>

            <div class="voiceprint-status" id="voiceprintStatus"></div>

            <div class="voiceprint-btns">
                <button id="startEnrollmentBtn" onclick="startVoiceprintEnrollment()">Start Recording</button>
                <button class="btn-secondary" onclick="skipVoiceprintEnrollment()">Skip</button>
            </div>
        </div>
    </div>

    <script>
        // ========================================
        // CONFIGURATION - Easy model switching
        // ========================================
        const CONFIG = {
            // OpenAI Realtime API Model
            // Options:
            // - 'gpt-4o-realtime-preview-2024-12-17'
            // - 'gpt-realtime-2025-08-28' (most capable)
            // - 'gpt-realtime-mini-2025-10-06' (faster, cheaper)
            model: 'gpt-realtime-mini-2025-10-06',

            // Voice settings
            voice: 'alloy',  // Options: alloy, echo, fable, onyx, nova, shimmer

            // Turn detection sensitivity (0.0 - 1.0)
            vadThreshold: 0.5,
            vadSilenceDuration: 500,  // milliseconds

            // Call Mode
            callMode: null,  // 'earpiece' or 'speaker', set by user

            // Voiceprint Recognition (Speaker Verification)
            enableVoiceprint: false,  // Will be set based on call mode and user choice
            voiceprintThreshold: 0.7,  // Similarity threshold (0.0-1.0), higher = stricter
            voiceprintEnrollmentText: 'Hello, I am registering my voice with VerifAIble. This is my unique voice signature.'
        };
        // ========================================

        const callStatus = document.getElementById('callStatus');
        const avatar = document.getElementById('avatar');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const transcriptEl = document.getElementById('transcript');
        const audioElement = document.getElementById('audioElement');

        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let audioQueue = [];
        let isPlaying = false;
        let nextPlayTime = 0;

        // Voiceprint variables
        let voiceprintProfile = null;  // Stored voiceprint features
        let isEnrolling = false;
        let enrollmentAudioData = [];
        let enrollmentAnalyser = null;
        let realtimeAudioBuffer = [];  // Buffer for realtime voice verification
        const BUFFER_SIZE = 4096;
        const VERIFICATION_INTERVAL = 1000;  // Check every 1 second

        // ========================================
        // VOICEPRINT FUNCTIONS
        // ========================================

        // Extract audio features (simplified MFCC-like features using FFT)
        function extractAudioFeatures(audioData) {
            const fftSize = 2048;
            const numMelBands = 40;
            const features = [];

            // Process audio in chunks
            for (let i = 0; i < audioData.length - fftSize; i += fftSize / 2) {
                const chunk = audioData.slice(i, i + fftSize);

                // Apply FFT (simplified - using frequency domain analysis)
                const spectrum = applyFFT(chunk);

                // Convert to Mel scale (simplified)
                const melBands = convertToMelScale(spectrum, numMelBands);

                features.push(melBands);
            }

            // Return averaged features
            return averageFeatures(features);
        }

        // Simplified FFT (using Web Audio API's AnalyserNode would be better, but this works for demo)
        function applyFFT(audioChunk) {
            const spectrum = new Array(audioChunk.length / 2).fill(0);

            for (let k = 0; k < spectrum.length; k++) {
                let real = 0;
                let imag = 0;

                for (let n = 0; n < audioChunk.length; n++) {
                    const angle = -2 * Math.PI * k * n / audioChunk.length;
                    real += audioChunk[n] * Math.cos(angle);
                    imag += audioChunk[n] * Math.sin(angle);
                }

                spectrum[k] = Math.sqrt(real * real + imag * imag);
            }

            return spectrum;
        }

        // Convert frequency spectrum to Mel scale
        function convertToMelScale(spectrum, numBands) {
            const melBands = new Array(numBands).fill(0);
            const bandSize = Math.floor(spectrum.length / numBands);

            for (let i = 0; i < numBands; i++) {
                const start = i * bandSize;
                const end = start + bandSize;

                for (let j = start; j < end && j < spectrum.length; j++) {
                    melBands[i] += spectrum[j];
                }

                melBands[i] /= bandSize;
            }

            return melBands;
        }

        // Average multiple feature vectors
        function averageFeatures(featuresList) {
            if (featuresList.length === 0) return null;

            const numFeatures = featuresList[0].length;
            const avgFeatures = new Array(numFeatures).fill(0);

            for (const features of featuresList) {
                for (let i = 0; i < numFeatures; i++) {
                    avgFeatures[i] += features[i];
                }
            }

            for (let i = 0; i < numFeatures; i++) {
                avgFeatures[i] /= featuresList.length;
            }

            return avgFeatures;
        }

        // Calculate cosine similarity between two feature vectors
        function cosineSimilarity(vec1, vec2) {
            if (!vec1 || !vec2 || vec1.length !== vec2.length) return 0;

            let dotProduct = 0;
            let mag1 = 0;
            let mag2 = 0;

            for (let i = 0; i < vec1.length; i++) {
                dotProduct += vec1[i] * vec2[i];
                mag1 += vec1[i] * vec1[i];
                mag2 += vec2[i] * vec2[i];
            }

            mag1 = Math.sqrt(mag1);
            mag2 = Math.sqrt(mag2);

            if (mag1 === 0 || mag2 === 0) return 0;

            return dotProduct / (mag1 * mag2);
        }

        // Verify if current speaker matches enrolled voiceprint
        function verifyVoiceprint(audioData) {
            if (!CONFIG.enableVoiceprint || !voiceprintProfile) {
                return true;  // Always pass if voiceprint is disabled or not enrolled
            }

            const currentFeatures = extractAudioFeatures(audioData);
            const similarity = cosineSimilarity(voiceprintProfile, currentFeatures);

            console.log(`Voice similarity: ${(similarity * 100).toFixed(1)}% (threshold: ${(CONFIG.voiceprintThreshold * 100).toFixed(1)}%)`);

            return similarity >= CONFIG.voiceprintThreshold;
        }

        // Load voiceprint from localStorage
        function loadVoiceprint() {
            const stored = localStorage.getItem('verifaible_voiceprint');
            if (stored) {
                try {
                    voiceprintProfile = JSON.parse(stored);
                    console.log('Voiceprint loaded from storage');
                    return true;
                } catch (e) {
                    console.error('Failed to load voiceprint:', e);
                }
            }
            return false;
        }

        // Save voiceprint to localStorage
        function saveVoiceprint(features) {
            voiceprintProfile = features;
            localStorage.setItem('verifaible_voiceprint', JSON.stringify(features));
            console.log('Voiceprint saved to storage');
            updateVoiceprintIndicator();
        }

        // Clear voiceprint
        function clearVoiceprint() {
            voiceprintProfile = null;
            localStorage.removeItem('verifaible_voiceprint');
            console.log('Voiceprint cleared');
            updateVoiceprintIndicator();
        }

        // Show voiceprint enrollment modal
        function showVoiceprintModal() {
            const modal = document.getElementById('voiceprintModal');
            const enrollmentText = document.getElementById('enrollmentText');

            enrollmentText.textContent = CONFIG.voiceprintEnrollmentText;
            modal.classList.add('show');
        }

        // Start voiceprint enrollment
        async function startVoiceprintEnrollment() {
            const recordingIndicator = document.getElementById('recordingIndicator');
            const startBtn = document.getElementById('startEnrollmentBtn');
            const statusEl = document.getElementById('voiceprintStatus');

            try {
                startBtn.disabled = true;
                recordingIndicator.classList.add('active');
                statusEl.textContent = 'Recording... Please read the text above clearly.';

                // Get microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                const source = audioCtx.createMediaStreamSource(stream);
                enrollmentAnalyser = audioCtx.createAnalyser();
                enrollmentAnalyser.fftSize = 2048;

                source.connect(enrollmentAnalyser);

                enrollmentAudioData = [];
                isEnrolling = true;

                // Capture audio for 5 seconds
                const captureInterval = setInterval(() => {
                    const dataArray = new Float32Array(enrollmentAnalyser.fftSize);
                    enrollmentAnalyser.getFloatTimeDomainData(dataArray);
                    enrollmentAudioData.push(...Array.from(dataArray));
                }, 100);

                setTimeout(() => {
                    clearInterval(captureInterval);
                    isEnrolling = false;

                    // Stop recording
                    stream.getTracks().forEach(track => track.stop());
                    audioCtx.close();

                    // Extract and save features
                    const features = extractAudioFeatures(enrollmentAudioData);

                    if (features && features.length > 0) {
                        saveVoiceprint(features);
                        statusEl.textContent = 'Voice registered successfully!';
                        statusEl.style.color = '#34d399';

                        setTimeout(() => {
                            hideVoiceprintModal();
                        }, 2000);
                    } else {
                        throw new Error('Failed to extract voice features');
                    }

                    recordingIndicator.classList.remove('active');
                    startBtn.disabled = false;
                }, 5000);

            } catch (error) {
                console.error('Enrollment failed:', error);
                statusEl.textContent = 'Failed to record. Please try again.';
                statusEl.style.color = '#ff3b30';
                recordingIndicator.classList.remove('active');
                startBtn.disabled = false;
            }
        }

        // Skip voiceprint enrollment
        function skipVoiceprintEnrollment() {
            hideVoiceprintModal();
        }

        // Hide voiceprint modal
        function hideVoiceprintModal() {
            const modal = document.getElementById('voiceprintModal');
            modal.classList.remove('show');
        }

        // Check if voiceprint enrollment is needed
        function checkVoiceprintEnrollment() {
            if (CONFIG.enableVoiceprint && !loadVoiceprint()) {
                showVoiceprintModal();
            }
        }

        // Update voiceprint indicator UI
        function updateVoiceprintIndicator() {
            const icon = document.getElementById('voiceprintIcon');
            const text = document.getElementById('voiceprintText');
            const indicator = document.getElementById('voiceprintIndicator');

            if (!CONFIG.callMode) {
                icon.classList.add('disabled');
                text.textContent = 'No Mode';
                indicator.title = 'Click to select call mode';
            } else if (CONFIG.callMode === 'earpiece') {
                icon.classList.remove('disabled');
                text.textContent = 'üì± Earpiece';
                indicator.title = 'Earpiece mode - Click to change';
            } else if (CONFIG.callMode === 'speaker') {
                if (CONFIG.enableVoiceprint) {
                    if (voiceprintProfile) {
                        icon.classList.remove('disabled');
                        text.textContent = 'üîä Protected';
                        indicator.title = 'Speaker + Voiceprint - Click to change';
                    } else {
                        icon.classList.add('disabled');
                        text.textContent = 'üîä Not Enrolled';
                        indicator.title = 'Click to register voiceprint';
                    }
                } else {
                    icon.classList.remove('disabled');
                    text.textContent = 'üîä Speaker';
                    indicator.title = 'Speaker mode - Click to change';
                }
            }
        }

        // Open settings (mode selection or voiceprint)
        function openSettings() {
            if (!CONFIG.callMode) {
                showModeModal();
            } else if (CONFIG.callMode === 'speaker' && CONFIG.enableVoiceprint && !voiceprintProfile) {
                // ÂÖçÊèê+Â£∞Á∫π‰ΩÜÊú™Ê≥®ÂÜåÔºöÊòæÁ§∫Â£∞Á∫πÊ≥®ÂÜå
                showVoiceprintModal();
            } else {
                // ÂÖ∂‰ªñÊÉÖÂÜµÔºöÈáçÊñ∞ÈÄâÊã©Ê®°Âºè
                showModeModal();
            }
        }

        // ========================================
        // CALL MODE SELECTION
        // ========================================

        let selectedMode = null;

        function showModeModal() {
            const modal = document.getElementById('modeModal');
            modal.classList.add('show');
        }

        function hideModeModal() {
            const modal = document.getElementById('modeModal');
            modal.classList.remove('show');
        }

        function selectMode(mode) {
            selectedMode = mode;

            // Update UI
            document.getElementById('earpieceMode').classList.remove('selected');
            document.getElementById('speakerMode').classList.remove('selected');

            if (mode === 'earpiece') {
                document.getElementById('earpieceMode').classList.add('selected');
                document.getElementById('modeWarning').style.display = 'none';
                // Âê¨Á≠íÊ®°ÂºèÁ¶ÅÁî®Â§çÈÄâÊ°Ü
                document.getElementById('enableVoiceprintCheck').disabled = true;
                document.getElementById('enableVoiceprintCheck').checked = false;
            } else if (mode === 'speaker') {
                document.getElementById('speakerMode').classList.add('selected');
                // ÂÖçÊèêÊ®°ÂºèÂêØÁî®Â§çÈÄâÊ°Ü
                document.getElementById('enableVoiceprintCheck').disabled = false;
                updateModeWarning();
            }
        }

        function updateModeWarning() {
            const voiceprintEnabled = document.getElementById('enableVoiceprintCheck').checked;
            const warning = document.getElementById('modeWarning');

            if (selectedMode === 'speaker' && !voiceprintEnabled) {
                warning.style.display = 'block';
            } else {
                warning.style.display = 'none';
            }
        }

        // ÁõëÂê¨Â§çÈÄâÊ°ÜÂèòÂåñ
        document.addEventListener('DOMContentLoaded', () => {
            const checkbox = document.getElementById('enableVoiceprintCheck');
            if (checkbox) {
                checkbox.addEventListener('change', updateModeWarning);
            }
        });

        function confirmMode() {
            if (!selectedMode) {
                alert('Please select a call mode');
                return;
            }

            const voiceprintCheckbox = document.getElementById('enableVoiceprintCheck');

            // Ê†πÊçÆÈÄâÊã©ÈÖçÁΩÆCONFIG
            CONFIG.callMode = selectedMode;

            if (selectedMode === 'earpiece') {
                // Âê¨Á≠íÊ®°ÂºèÔºö‰∏çÈúÄË¶ÅÂ£∞Á∫πËØÜÂà´
                CONFIG.enableVoiceprint = false;
                console.log('Earpiece mode selected - voiceprint disabled');

                hideModeModal();
                updateVoiceprintIndicator();

            } else if (selectedMode === 'speaker') {
                // ÂÖçÊèêÊ®°ÂºèÔºöÊ†πÊçÆÁî®Êà∑ÈÄâÊã©
                CONFIG.enableVoiceprint = voiceprintCheckbox.checked;
                console.log(`Speaker mode selected - voiceprint ${CONFIG.enableVoiceprint ? 'enabled' : 'disabled'}`);

                hideModeModal();

                // Â¶ÇÊûúÂêØÁî®Â£∞Á∫πÔºåÊ£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÊ≥®ÂÜå
                if (CONFIG.enableVoiceprint) {
                    checkVoiceprintEnrollment();
                }

                updateVoiceprintIndicator();
            }

            // ‰øùÂ≠òÂà∞localStorage
            localStorage.setItem('verifaible_call_mode', selectedMode);
            localStorage.setItem('verifaible_voiceprint_enabled', CONFIG.enableVoiceprint);
        }

        function loadSavedMode() {
            const savedMode = localStorage.getItem('verifaible_call_mode');
            const savedVoiceprintEnabled = localStorage.getItem('verifaible_voiceprint_enabled');

            if (savedMode) {
                CONFIG.callMode = savedMode;
                CONFIG.enableVoiceprint = savedVoiceprintEnabled === 'true';
                console.log(`Loaded saved mode: ${savedMode}, voiceprint: ${CONFIG.enableVoiceprint}`);
                return true;
            }

            return false;
        }

        // ========================================
        // END CALL MODE SELECTION
        // ========================================

        // Initialize on page load
        window.addEventListener('DOMContentLoaded', () => {
            // Ê£ÄÊü•ÊòØÂê¶Êúâ‰øùÂ≠òÁöÑÊ®°ÂºèËÆæÁΩÆ
            if (!loadSavedMode()) {
                // È¶ñÊ¨°ËÆøÈóÆÔºåÊòæÁ§∫Ê®°ÂºèÈÄâÊã©
                showModeModal();
            } else {
                // Â∑≤ÊúâËÆæÁΩÆÔºåÊ£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÂ£∞Á∫πÊ≥®ÂÜå
                if (CONFIG.enableVoiceprint) {
                    checkVoiceprintEnrollment();
                }
            }

            updateVoiceprintIndicator();
        });

        // ========================================
        // END VOICEPRINT FUNCTIONS
        // ========================================

        function addMessage(role, text) {
            const msg = document.createElement('div');
            msg.className = `message ${role}`;
            msg.textContent = text;
            transcriptEl.appendChild(msg);
            transcriptEl.scrollTop = transcriptEl.scrollHeight;
        }

        function updateStatus(text, isPulse = false) {
            callStatus.textContent = text;
            if (isPulse) {
                avatar.classList.add('pulse');
            } else {
                avatar.classList.remove('pulse');
            }
        }

        async function playAudioChunk(base64Audio) {
            if (!audioContext) return;

            try {
                // Ëß£Á†Åbase64Èü≥È¢ë
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // ËΩ¨Êç¢‰∏∫AudioBuffer (PCM16, 24kHz, mono)
                const int16Array = new Int16Array(bytes.buffer);
                const float32Array = new Float32Array(int16Array.length);
                for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768.0;
                }

                const audioBuffer = audioContext.createBuffer(1, float32Array.length, 24000);
                audioBuffer.getChannelData(0).set(float32Array);

                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                // ËÆ°ÁÆóÊ≠£Á°ÆÁöÑÊí≠ÊîæÊó∂Èó¥ÔºåÁ°Æ‰øùÈü≥È¢ëÂùóËøûÁª≠Êí≠Êîæ‰∏çÈáçÂè†
                const currentTime = audioContext.currentTime;
                const startTime = Math.max(currentTime, nextPlayTime);

                source.start(startTime);

                // Êõ¥Êñ∞‰∏ã‰∏Ä‰∏™Èü≥È¢ëÂùóÂ∫îËØ•ÂºÄÂßãÁöÑÊó∂Èó¥
                nextPlayTime = startTime + audioBuffer.duration;
            } catch (err) {
                console.error('Êí≠ÊîæÈü≥È¢ëÂ§±Ë¥•:', err);
            }
        }

        async function connect() {
            // Ê£ÄÊü•ÊòØÂê¶Â∑≤ÈÄâÊã©ÈÄöËØùÊ®°Âºè
            if (!CONFIG.callMode) {
                showModeModal();
                return;
            }

            // Â¶ÇÊûúÂêØÁî®Â£∞Á∫π‰ΩÜÊú™Ê≥®ÂÜåÔºåÊòæÁ§∫Ê≥®ÂÜåÊ®°ÊÄÅÊ°Ü
            if (CONFIG.enableVoiceprint && !voiceprintProfile) {
                showVoiceprintModal();
                return;
            }

            try {
                connectBtn.disabled = true;
                updateStatus('Connecting...', false);

                // Ëé∑ÂèñAPIÂØÜÈí•
                const keyResponse = await fetch('/api_key');
                const keyData = await keyResponse.json();
                const apiKey = keyData.api_key;

                addMessage('system', 'Ê≠£Âú®ËøûÊé•Âà∞OpenAI Realtime API...');

                // ËøûÊé•WebSocket (ÊåâÁÖßÂÆòÊñπÊñáÊ°£Ê†ºÂºè)
                ws = new WebSocket(
                    `wss://api.openai.com/v1/realtime?model=${CONFIG.model}`,
                    [
                        'realtime',
                        'openai-insecure-api-key.' + apiKey,
                        'openai-beta.realtime-v1'
                    ]
                );

                ws.onopen = async () => {

                    // ÈÖçÁΩÆ‰ºöËØù
                    ws.send(JSON.stringify({
                        type: 'session.update',
                        session: {
                            modalities: ['text', 'audio'],
                            instructions: 'You are a friendly AI voice assistant. You can help users find the websites and information they need through voice. When users ask questions or want to query information, you should: 1. Understand user intent 2. Use the recognize_intent tool to identify the most suitable website 3. Naturally tell users the results, including recommended website URLs. Keep conversations natural, friendly, and efficient.',
                            voice: CONFIG.voice,
                            input_audio_format: 'pcm16',
                            output_audio_format: 'pcm16',
                            input_audio_transcription: {
                                model: 'whisper-1'
                            },
                            turn_detection: {
                                type: 'server_vad',
                                threshold: CONFIG.vadThreshold,
                                prefix_padding_ms: 300,
                                silence_duration_ms: CONFIG.vadSilenceDuration
                            },
                            tools: [
                                {
                                    type: 'function',
                                    name: 'recognize_intent',
                                    description: 'ËØÜÂà´Áî®Êà∑Êü•ËØ¢ÊÑèÂõæÂπ∂ËøîÂõûÊúÄÂêàÈÄÇÁöÑÁΩëÁ´ôURL„ÄÇÂΩìÁî®Êà∑ËØ¢ÈóÆË¶ÅÊü•ËØ¢Êüê‰∫õ‰ø°ÊÅØ„ÄÅËÆøÈóÆÊüê‰∏™ÁΩëÁ´ô„ÄÅÊàñÂØªÊâæÊüêÁ±ªÊúçÂä°Êó∂Ôºå‰ΩøÁî®Ê≠§Â∑•ÂÖ∑„ÄÇ',
                                    parameters: {
                                        type: 'object',
                                        properties: {
                                            query: {
                                                type: 'string',
                                                description: 'Áî®Êà∑ÁöÑÊü•ËØ¢ÊñáÊú¨Ôºå‰æãÂ¶Ç\'PythonÊïôÁ®ã\'„ÄÅ\'Ë¥µÂ∑ûËåÖÂè∞ËÇ°Á•®\'„ÄÅ\'‰∏™‰∫∫ÊâÄÂæóÁ®éËÆ°ÁÆó\'Á≠â'
                                            },
                                            top_k: {
                                                type: 'integer',
                                                description: 'ËøîÂõûtop-k‰∏™ÂèØËÉΩÁöÑÁªìÊûúÔºåÈªòËÆ§3',
                                                default: 3
                                            }
                                        },
                                        required: ['query']
                                    }
                                }
                            ],
                            tool_choice: 'auto'
                        }
                    }));

                    // Ëé∑ÂèñÈ∫¶ÂÖãÈ£é
                    try {
                        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                        // ËÆæÁΩÆÈü≥È¢ë‰∏ä‰∏ãÊñá (24kHzÈááÊ†∑Áéá)
                        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                        const source = audioContext.createMediaStreamSource(mediaStream);
                        const processor = audioContext.createScriptProcessor(2048, 1, 1);

                        source.connect(processor);
                        processor.connect(audioContext.destination);

                        let lastVerificationTime = 0;
                        let voiceprintVerified = !CONFIG.enableVoiceprint;  // Auto-pass if disabled

                        processor.onaudioprocess = (e) => {
                            if (ws && ws.readyState === WebSocket.OPEN) {
                                const inputData = e.inputBuffer.getChannelData(0);

                                // Add to realtime buffer for voiceprint verification
                                realtimeAudioBuffer.push(...Array.from(inputData));

                                // Periodic voiceprint verification
                                const now = Date.now();
                                if (CONFIG.enableVoiceprint && (now - lastVerificationTime) >= VERIFICATION_INTERVAL) {
                                    lastVerificationTime = now;

                                    if (realtimeAudioBuffer.length >= BUFFER_SIZE) {
                                        // Verify voiceprint
                                        const bufferToVerify = realtimeAudioBuffer.slice(-BUFFER_SIZE);
                                        voiceprintVerified = verifyVoiceprint(bufferToVerify);

                                        if (!voiceprintVerified) {
                                            console.warn('Voice verification failed - audio not sent');
                                            // Clear buffer to prevent sending unverified audio
                                            realtimeAudioBuffer = [];
                                            return;
                                        }
                                    }
                                }

                                // Keep buffer size manageable
                                if (realtimeAudioBuffer.length > BUFFER_SIZE * 2) {
                                    realtimeAudioBuffer = realtimeAudioBuffer.slice(-BUFFER_SIZE);
                                }

                                // Only send audio if voiceprint is verified (or disabled)
                                if (voiceprintVerified || !CONFIG.enableVoiceprint) {
                                    const pcm16 = new Int16Array(inputData.length);
                                    for (let i = 0; i < inputData.length; i++) {
                                        pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                                    }

                                    // ËΩ¨‰∏∫base64Âπ∂ÂèëÈÄÅ
                                    const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                                    ws.send(JSON.stringify({
                                        type: 'input_audio_buffer.append',
                                        audio: base64
                                    }));
                                }
                            }
                        };

                        updateStatus('In call', true);
                        disconnectBtn.disabled = false;

                    } catch (err) {
                        updateStatus('Microphone permission denied', false);
                        connectBtn.disabled = false;
                    }
                };

                ws.onmessage = async (event) => {
                    const data = JSON.parse(event.data);
                    console.log('Êî∂Âà∞‰∫ã‰ª∂:', data.type, data);

                    // Â§ÑÁêÜÁî®Êà∑ËØ¥ËØùËΩ¨ÂΩï
                    if (data.type === 'conversation.item.input_audio_transcription.completed') {
                        addMessage('user', data.transcript);
                    }

                    // Â§ÑÁêÜAIÂõûÂ§çËΩ¨ÂΩï
                    if (data.type === 'response.audio_transcript.done') {
                        addMessage('assistant', data.transcript);
                    }

                    // Â§ÑÁêÜAIÈü≥È¢ëËæìÂá∫
                    if (data.type === 'response.audio.delta' && data.delta) {
                        await playAudioChunk(data.delta);
                    }

                    // Â§ÑÁêÜÂáΩÊï∞Ë∞ÉÁî®
                    if (data.type === 'response.function_call_arguments.done') {

                        if (data.name === 'recognize_intent') {
                            try {
                                const args = JSON.parse(data.arguments);
                                const result = await fetch('/recognize_intent', {
                                    method: 'POST',
                                    headers: { 'Content-Type': 'application/json' },
                                    body: JSON.stringify(args)
                                });
                                const resultData = await result.json();

                                // ÂèëÈÄÅÂ∑•ÂÖ∑ÁªìÊûú
                                ws.send(JSON.stringify({
                                    type: 'conversation.item.create',
                                    item: {
                                        type: 'function_call_output',
                                        call_id: data.call_id,
                                        output: JSON.stringify(resultData, null, 2)
                                    }
                                }));

                                // Ëß¶ÂèëÂìçÂ∫î
                                ws.send(JSON.stringify({ type: 'response.create' }));

                                // ‰øùÂ≠òÂà∞ÂéÜÂè≤ËÆ∞ÂΩï
                                const categories = resultData.predictions?.map(p => p.category).join('„ÄÅ') || 'N/A';
                                addMessage('system', `Êé®Ëçê: ${categories}`);
                            } catch (err) {
                                console.error('Â∑•ÂÖ∑Ë∞ÉÁî®Â§±Ë¥•:', err);
                            }
                        }
                    }

                    // Â§ÑÁêÜÈîôËØØ
                    if (data.type === 'error') {
                        console.error('ÊúçÂä°Âô®ÈîôËØØ:', data.error);
                    }
                };

                ws.onerror = (error) => {
                    console.error('WebSocketÈîôËØØ:', error);
                    updateStatus('Connection error', false);
                };

                ws.onclose = () => {
                    updateStatus('Click to start conversation', false);
                    connectBtn.disabled = false;
                    disconnectBtn.disabled = true;

                    if (mediaStream) {
                        mediaStream.getTracks().forEach(track => track.stop());
                    }
                    if (audioContext) {
                        audioContext.close();
                    }
                };

            } catch (error) {
                console.error('ËøûÊé•ÈîôËØØ:', error);
                updateStatus('Connection failed', false);
                connectBtn.disabled = false;
            }
        }

        function disconnect() {
            if (ws) {
                ws.close();
                ws = null;
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            // ÈáçÁΩÆÈü≥È¢ëÊí≠ÊîæÊó∂Èó¥
            nextPlayTime = 0;
            // Ê∏ÖÁ©∫Â£∞Á∫πÁºìÂÜ≤Âå∫
            realtimeAudioBuffer = [];
            updateStatus('Click to start conversation', false);
            connectBtn.disabled = false;
            disconnectBtn.disabled = true;
        }

        connectBtn.addEventListener('click', connect);
        disconnectBtn.addEventListener('click', disconnect);
    </script>
</body>
</html>
