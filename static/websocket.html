<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>VerifAIble</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', 'Helvetica Neue', Arial, sans-serif;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 0;
            overflow: hidden;
            position: relative;
        }

        /* èƒŒæ™¯å›¾ç‰‡é«˜æ–¯æ¨¡ç³Š */
        body::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: linear-gradient(135deg, #34d399 0%, #059669 100%);
            background-size: cover;
            background-position: center;
            filter: blur(80px);
            transform: scale(1.1);
            z-index: -2;
        }

        body::after {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.4);
            z-index: -1;
        }

        /* é€šè¯å±å¹• */
        .call-screen {
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: space-between;
            padding: 80px 40px 60px;
        }

        /* å¤´åƒåŒºåŸŸ */
        .avatar-section {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }

        .avatar {
            width: 180px;
            height: 180px;
            border-radius: 50%;
            background: linear-gradient(135deg, #34d399 0%, #059669 100%);
            background-size: cover;
            background-position: center;
            margin-bottom: 30px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
            border: 4px solid rgba(255, 255, 255, 0.2);
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .avatar.pulse {
            animation: avatarPulse 2s infinite;
        }

        @keyframes avatarPulse {
            0%, 100% {
                transform: scale(1);
                box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
            }
            50% {
                transform: scale(1.05);
                box-shadow: 0 20px 80px rgba(52, 211, 153, 0.8);
            }
        }

        .caller-name {
            font-size: 42px;
            font-weight: 200;
            color: #ffffff;
            margin-bottom: 16px;
            letter-spacing: 1px;
            text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        .call-status {
            font-size: 18px;
            color: rgba(255, 255, 255, 0.7);
            font-weight: 300;
            letter-spacing: 0.5px;
            text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        /* æ§åˆ¶æŒ‰é’®åŒºåŸŸ */
        .controls {
            display: flex;
            justify-content: center;
            gap: 80px;
            padding: 20px 0;
        }

        .control-btn {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s;
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.4);
            position: relative;
        }

        .control-btn::before {
            content: '';
            position: absolute;
            width: 100%;
            height: 100%;
            border-radius: 50%;
            background: inherit;
            filter: blur(20px);
            opacity: 0.6;
            z-index: -1;
        }

        .control-btn:active {
            transform: scale(0.95);
        }

        .control-btn:disabled {
            opacity: 0.4;
            cursor: not-allowed;
        }

        .btn-call {
            background: #34c759;
            font-size: 36px;
        }

        .btn-call:hover:not(:disabled) {
            background: #30b350;
            transform: scale(1.05);
        }

        .btn-end {
            background: #ff3b30;
            font-size: 36px;
        }

        .btn-end:hover:not(:disabled) {
            background: #e6342a;
            transform: scale(1.05);
        }

        /* å¯¹è¯è®°å½•éšè— */
        .transcript {
            display: none;
        }

        /* å£°çº¹æ³¨å†Œæ¨¡æ€æ¡† */
        .voiceprint-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.7);
            z-index: 1000;
            justify-content: center;
            align-items: center;
        }

        .voiceprint-modal.show {
            display: flex;
        }

        .voiceprint-content {
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(20px);
            border-radius: 30px;
            padding: 50px 40px;
            max-width: 500px;
            width: 90%;
            border: 1px solid rgba(255, 255, 255, 0.2);
            text-align: center;
        }

        .voiceprint-content h2 {
            font-size: 28px;
            font-weight: 300;
            color: #ffffff;
            margin-bottom: 20px;
            text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        .voiceprint-content p {
            font-size: 16px;
            color: rgba(255, 255, 255, 0.8);
            margin-bottom: 30px;
            line-height: 1.6;
        }

        .enrollment-text {
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            font-size: 18px;
            color: white;
            line-height: 1.8;
        }

        .recording-indicator {
            display: none;
            margin: 20px 0;
        }

        .recording-indicator.active {
            display: block;
        }

        .pulse-ring {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            background: rgba(255, 59, 48, 0.3);
            margin: 0 auto;
            position: relative;
            animation: pulseRing 1.5s infinite;
        }

        .pulse-ring::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: #ff3b30;
        }

        @keyframes pulseRing {
            0%, 100% {
                transform: scale(1);
                opacity: 1;
            }
            50% {
                transform: scale(1.2);
                opacity: 0.7;
            }
        }

        .voiceprint-btns {
            display: flex;
            gap: 15px;
            margin-top: 30px;
        }

        .voiceprint-btns button {
            flex: 1;
            padding: 18px 30px;
            background: white;
            color: #333;
            border: none;
            border-radius: 50px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.3);
        }

        .voiceprint-btns button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 12px 32px rgba(0, 0, 0, 0.4);
        }

        .voiceprint-btns button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .voiceprint-btns .btn-secondary {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border: 1px solid rgba(255, 255, 255, 0.3);
        }

        .voiceprint-status {
            margin-top: 15px;
            font-size: 14px;
            color: rgba(255, 255, 255, 0.7);
        }

        /* Voiceprint indicator (top right corner) */
        .voiceprint-indicator {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(20px);
            border-radius: 20px;
            padding: 10px 20px;
            border: 1px solid rgba(255, 255, 255, 0.2);
            display: flex;
            align-items: center;
            gap: 10px;
            z-index: 100;
            cursor: pointer;
            transition: all 0.3s;
        }

        .voiceprint-indicator:hover {
            background: rgba(255, 255, 255, 0.25);
        }

        .voiceprint-indicator .status-icon {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #34d399;
        }

        .voiceprint-indicator .status-icon.disabled {
            background: #6b7280;
        }

        .voiceprint-indicator .status-text {
            font-size: 14px;
            color: white;
            font-weight: 500;
        }

        /* é€šè¯æ¨¡å¼é€‰æ‹©æ¨¡æ€æ¡† */
        .mode-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.7);
            z-index: 2000;
            justify-content: center;
            align-items: center;
        }

        .mode-modal.show {
            display: flex;
        }

        .mode-content {
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(20px);
            border-radius: 30px;
            padding: 40px 35px;
            max-width: 450px;
            width: 90%;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .mode-content h2 {
            font-size: 24px;
            font-weight: 300;
            color: #ffffff;
            margin-bottom: 25px;
            text-align: center;
            text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        .mode-option {
            background: rgba(255, 255, 255, 0.1);
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 15px;
            cursor: pointer;
            transition: all 0.3s;
        }

        .mode-option:hover {
            background: rgba(255, 255, 255, 0.2);
            border-color: rgba(255, 255, 255, 0.5);
            transform: translateY(-2px);
        }

        .mode-option.selected {
            background: rgba(52, 211, 153, 0.3);
            border-color: #34d399;
        }

        .mode-option-header {
            display: flex;
            align-items: center;
            gap: 12px;
            margin-bottom: 10px;
        }

        .mode-icon {
            font-size: 28px;
        }

        .mode-title {
            font-size: 18px;
            font-weight: 600;
            color: white;
        }

        .mode-badge {
            background: #34d399;
            color: white;
            font-size: 11px;
            padding: 3px 8px;
            border-radius: 10px;
            font-weight: 600;
            margin-left: auto;
        }

        .mode-description {
            font-size: 14px;
            color: rgba(255, 255, 255, 0.8);
            line-height: 1.5;
            margin-left: 40px;
        }

        .voiceprint-option {
            margin-top: 12px;
            margin-left: 40px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .voiceprint-option input[type="checkbox"] {
            width: 20px;
            height: 20px;
            cursor: pointer;
        }

        .voiceprint-option label {
            font-size: 14px;
            color: white;
            cursor: pointer;
            user-select: none;
        }

        .mode-warning {
            background: rgba(245, 158, 11, 0.2);
            border: 1px solid rgba(245, 158, 11, 0.4);
            border-radius: 10px;
            padding: 12px;
            margin-top: 20px;
            font-size: 13px;
            color: rgba(255, 255, 255, 0.9);
            line-height: 1.5;
        }

        .mode-warning-icon {
            display: inline-block;
            margin-right: 5px;
        }

        .mode-buttons {
            display: flex;
            gap: 10px;
            margin-top: 25px;
        }

        .mode-buttons button {
            flex: 1;
            padding: 15px;
            background: white;
            color: #333;
            border: none;
            border-radius: 50px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .mode-buttons button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);
        }

        .mode-buttons button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }
    </style>
</head>
<body>
    <!-- Voiceprint status indicator -->
    <div class="voiceprint-indicator" id="voiceprintIndicator" onclick="openSettings()" title="Click to change settings">
        <div class="status-icon" id="voiceprintIcon"></div>
        <div class="status-text" id="voiceprintText">Mode</div>
    </div>

    <!-- é€šè¯å±å¹• -->
    <div class="call-screen">
        <!-- å¤´åƒåŒºåŸŸ -->
        <div class="avatar-section">
            <div id="avatar" class="avatar">
                <span style="font-size: 52px; font-weight: 300; color: white; text-shadow: 0 2px 8px rgba(0,0,0,0.3);">VAI</span>
            </div>
            <div class="caller-name">VerifAIble</div>
            <div id="callStatus" class="call-status">Click to start conversation</div>
        </div>

        <!-- å¯¹è¯è®°å½•ï¼ˆéšè—ï¼Œä»…ç”¨äºä¿å­˜å†å²ï¼‰ -->
        <div class="transcript" id="transcript"></div>

        <!-- æ§åˆ¶æŒ‰é’® -->
        <div class="controls">
            <button id="connectBtn" class="control-btn btn-call">
                â˜
            </button>
            <button id="disconnectBtn" class="control-btn btn-end" disabled>
                âœ•
            </button>
        </div>
    </div>

    <audio id="audioElement" autoplay></audio>

    <!-- é€šè¯æ¨¡å¼é€‰æ‹©æ¨¡æ€æ¡† -->
    <div id="modeModal" class="mode-modal">
        <div class="mode-content">
            <h2>ğŸ“ Select Call Mode</h2>

            <!-- å¬ç­’æ¨¡å¼ -->
            <div class="mode-option" id="earpieceMode" onclick="selectMode('earpiece')">
                <div class="mode-option-header">
                    <span class="mode-icon">ğŸ“±</span>
                    <span class="mode-title">Earpiece Mode</span>
                    <span class="mode-badge">Recommended</span>
                </div>
                <div class="mode-description">
                    Hold phone close to ear, like a regular call<br>
                    âœ“ More private<br>
                    âœ“ Auto noise filtering<br>
                    âœ“ No voiceprint needed
                </div>
            </div>

            <!-- å…ææ¨¡å¼ -->
            <div class="mode-option" id="speakerMode" onclick="selectMode('speaker')">
                <div class="mode-option-header">
                    <span class="mode-icon">ğŸ”Š</span>
                    <span class="mode-title">Speaker Mode</span>
                </div>
                <div class="mode-description">
                    Hands-free, suitable for open environments
                </div>
                <div class="voiceprint-option">
                    <input type="checkbox" id="enableVoiceprintCheck" onclick="event.stopPropagation()">
                    <label for="enableVoiceprintCheck" onclick="event.stopPropagation()">
                        Enable voiceprint verification (filter other voices)
                    </label>
                </div>
            </div>

            <div class="mode-warning" id="modeWarning" style="display: none;">
                <span class="mode-warning-icon">âš ï¸</span>
                <strong>Note:</strong> Speaker mode without voiceprint may pick up other voices,
                which could confuse the AI. Consider enabling voiceprint for better experience.
            </div>

            <div class="mode-buttons">
                <button onclick="confirmMode()">Confirm</button>
            </div>
        </div>
    </div>

    <!-- å£°çº¹æ³¨å†Œæ¨¡æ€æ¡† -->
    <div id="voiceprintModal" class="voiceprint-modal">
        <div class="voiceprint-content">
            <h2>ğŸ¤ Voice Registration</h2>
            <p>Please read the text below clearly. You can read both languages or just one - whichever you're comfortable with.</p>

            <div class="enrollment-text">
                <p style="margin-bottom: 15px;"><strong>ä¸­æ–‡æ®µè½ï¼š</strong><br>
                æˆ‘ä»¬çš„å®‡å®™è¯ç”Ÿäºçº¦ä¸€ç™¾ä¸‰åå…«äº¿å¹´å‰ã€‚ä»é‚£ä¸€åˆ»èµ·ï¼Œå®ƒå°±å¤„åœ¨æŒç»­çš„è†¨èƒ€ä¹‹ä¸­ï¼Œç©ºé—´æœ¬èº«åœ¨ä¸æ–­å»¶ä¼¸ã€‚æ˜Ÿç³»åœ¨å½¼æ­¤è¿œç¦»ï¼Œå°±åƒä¸€ä¸ªæ­£åœ¨è¢«å¹å¤§çš„æ°”çƒè¡¨é¢çš„ç‚¹ã€‚è¿™ç§è†¨èƒ€æ˜¯å®‡å®™æ¼”åŒ–çš„åŸºæœ¬é©±åŠ¨åŠ›ä¹‹ä¸€ï¼Œå†³å®šäº†å®ƒçš„è¿‡å»ä¸æœªæ¥ã€‚</p>

                <p><strong>English Paragraph:</strong><br>
                Our universe was born approximately 13.8 billion years ago. Since that moment, it has been in a state of continuous expansion, with space itself stretching. Galaxies are moving away from each other, like points on the surface of a balloon being inflated. This expansion is one of the fundamental drivers of cosmic evolution, defining its past and its future.</p>
            </div>

            <div class="recording-indicator" id="recordingIndicator" style="display: none;">
                <div class="pulse-ring"></div>
                <p style="margin-top: 15px; color: white;">Recording: <span id="enrollmentTimer">0:00</span></p>
            </div>

            <div class="voiceprint-status" id="voiceprintStatus"></div>

            <div class="voiceprint-btns">
                <button id="startEnrollmentBtn" onclick="toggleEnrollmentRecording()">
                    <span id="enrollmentBtnIcon">âºï¸</span>
                    <span id="enrollmentBtnText">Start Recording</span>
                </button>
                <button class="btn-secondary" onclick="skipVoiceprintEnrollment()">Skip</button>
            </div>
        </div>
    </div>

    <script>
        // ========================================
        // CONFIGURATION - Easy model switching
        // ========================================
        const CONFIG = {
            // OpenAI Realtime API Model
            // Options:
            // - 'gpt-4o-realtime-preview-2024-12-17'
            // - 'gpt-realtime-2025-08-28' (most capable)
            // - 'gpt-realtime-mini-2025-10-06' (faster, cheaper)
            model: 'gpt-realtime-mini-2025-10-06',

            // Voice settings
            voice: 'alloy',  // Options: alloy, echo, fable, onyx, nova, shimmer

            // Turn detection sensitivity (0.0 - 1.0)
            vadThreshold: 0.5,
            vadSilenceDuration: 500,  // milliseconds

            // Call Mode
            callMode: null,  // 'earpiece' or 'speaker', set by user

            // Voiceprint Recognition (Speaker Verification)
            enableVoiceprint: false,  // Will be set based on call mode and user choice
            voiceprintThreshold: 0.85,  // Similarity threshold (0.0-1.0), higher = stricter
            voiceprintCooldownPeriod: 15000,  // Cooldown period in ms after failed verification (15 seconds)
            voiceprintEnrollmentText: 'Hello, I am registering my voice with VerifAIble. This is my unique voice signature.'
        };
        // ========================================

        const callStatus = document.getElementById('callStatus');
        const avatar = document.getElementById('avatar');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const transcriptEl = document.getElementById('transcript');
        const audioElement = document.getElementById('audioElement');

        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let audioQueue = [];
        let isPlaying = false;
        let nextPlayTime = 0;
        let currentUserName = 'User';  // Will be loaded from server

        // Voiceprint variables
        let voiceprintProfile = null;  // Stored voiceprint features
        let isEnrolling = false;
        let enrollmentAudioData = [];
        let enrollmentAnalyser = null;
        let realtimeAudioBuffer = [];  // Buffer for realtime voice verification
        const BUFFER_SIZE = 4096;
        const VERIFICATION_INTERVAL = 1000;  // Check every 1 second

        // ========================================
        // VOICEPRINT FUNCTIONS
        // ========================================

        // Extract audio features (simplified MFCC-like features using FFT)
        function extractAudioFeatures(audioData) {
            const fftSize = 2048;
            const numMelBands = 40;
            const features = [];

            // Process audio in chunks
            for (let i = 0; i < audioData.length - fftSize; i += fftSize / 2) {
                const chunk = audioData.slice(i, i + fftSize);

                // Apply FFT (simplified - using frequency domain analysis)
                const spectrum = applyFFT(chunk);

                // Convert to Mel scale (simplified)
                const melBands = convertToMelScale(spectrum, numMelBands);

                features.push(melBands);
            }

            // Return averaged features
            return averageFeatures(features);
        }

        // Simplified FFT (using Web Audio API's AnalyserNode would be better, but this works for demo)
        function applyFFT(audioChunk) {
            const spectrum = new Array(audioChunk.length / 2).fill(0);

            for (let k = 0; k < spectrum.length; k++) {
                let real = 0;
                let imag = 0;

                for (let n = 0; n < audioChunk.length; n++) {
                    const angle = -2 * Math.PI * k * n / audioChunk.length;
                    real += audioChunk[n] * Math.cos(angle);
                    imag += audioChunk[n] * Math.sin(angle);
                }

                spectrum[k] = Math.sqrt(real * real + imag * imag);
            }

            return spectrum;
        }

        // Convert frequency spectrum to Mel scale
        function convertToMelScale(spectrum, numBands) {
            const melBands = new Array(numBands).fill(0);
            const bandSize = Math.floor(spectrum.length / numBands);

            for (let i = 0; i < numBands; i++) {
                const start = i * bandSize;
                const end = start + bandSize;

                for (let j = start; j < end && j < spectrum.length; j++) {
                    melBands[i] += spectrum[j];
                }

                melBands[i] /= bandSize;
            }

            return melBands;
        }

        // Average multiple feature vectors
        function averageFeatures(featuresList) {
            if (featuresList.length === 0) return null;

            const numFeatures = featuresList[0].length;
            const avgFeatures = new Array(numFeatures).fill(0);

            for (const features of featuresList) {
                for (let i = 0; i < numFeatures; i++) {
                    avgFeatures[i] += features[i];
                }
            }

            for (let i = 0; i < numFeatures; i++) {
                avgFeatures[i] /= featuresList.length;
            }

            return avgFeatures;
        }

        // Calculate cosine similarity between two feature vectors
        function cosineSimilarity(vec1, vec2) {
            if (!vec1 || !vec2 || vec1.length !== vec2.length) return 0;

            let dotProduct = 0;
            let mag1 = 0;
            let mag2 = 0;

            for (let i = 0; i < vec1.length; i++) {
                dotProduct += vec1[i] * vec2[i];
                mag1 += vec1[i] * vec1[i];
                mag2 += vec2[i] * vec2[i];
            }

            mag1 = Math.sqrt(mag1);
            mag2 = Math.sqrt(mag2);

            if (mag1 === 0 || mag2 === 0) return 0;

            return dotProduct / (mag1 * mag2);
        }

        // Verify if current speaker matches enrolled voiceprint
        function verifyVoiceprint(audioData) {
            if (!CONFIG.enableVoiceprint || !voiceprintProfile) {
                return true;  // Always pass if voiceprint is disabled or not enrolled
            }

            const currentFeatures = extractAudioFeatures(audioData);
            const similarity = cosineSimilarity(voiceprintProfile, currentFeatures);

            console.log(`Voice similarity: ${(similarity * 100).toFixed(1)}% (threshold: ${(CONFIG.voiceprintThreshold * 100).toFixed(1)}%)`);

            return similarity >= CONFIG.voiceprintThreshold;
        }

        // Load voiceprint from server
        async function loadVoiceprint() {
            try {
                const response = await fetch('/auth/user/voiceprint');
                if (!response.ok) {
                    console.error('Failed to load voiceprint from server');
                    return false;
                }

                const data = await response.json();
                if (data.has_voiceprint && data.voiceprint_profile) {
                    voiceprintProfile = JSON.parse(data.voiceprint_profile);
                    console.log('Voiceprint loaded from server');
                    return true;
                }
            } catch (e) {
                console.error('Failed to load voiceprint:', e);
            }
            return false;
        }

        // Save voiceprint to server
        async function saveVoiceprint(features) {
            try {
                const response = await fetch('/auth/user/voiceprint', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        voiceprint_profile: JSON.stringify(features),
                        call_mode: CONFIG.callMode,
                        voiceprint_enabled: CONFIG.enableVoiceprint
                    })
                });

                if (response.ok) {
                    voiceprintProfile = features;
                    console.log('Voiceprint saved to server');
                    updateVoiceprintIndicator();
                    return true;
                } else {
                    console.error('Failed to save voiceprint to server');
                    return false;
                }
            } catch (e) {
                console.error('Failed to save voiceprint:', e);
                return false;
            }
        }

        // Clear voiceprint from server
        async function clearVoiceprint() {
            try {
                const response = await fetch('/auth/user/voiceprint', {
                    method: 'DELETE'
                });

                if (response.ok) {
                    voiceprintProfile = null;
                    console.log('Voiceprint cleared from server');
                    updateVoiceprintIndicator();
                    return true;
                }
            } catch (e) {
                console.error('Failed to clear voiceprint:', e);
            }
            return false;
        }

        // Show voiceprint enrollment modal
        function showVoiceprintModal() {
            const modal = document.getElementById('voiceprintModal');
            modal.classList.add('show');

            // Reset UI
            document.getElementById('recordingIndicator').style.display = 'none';
            document.getElementById('voiceprintStatus').textContent = '';
            document.getElementById('enrollmentBtnIcon').textContent = 'âºï¸';
            document.getElementById('enrollmentBtnText').textContent = 'Start Recording';
        }

        // Toggle enrollment recording (start/stop)
        let enrollmentRecordingStartTime = null;
        let enrollmentRecordingTimer = null;
        let enrollmentMediaStream = null;
        let enrollmentAudioContext = null;

        async function toggleEnrollmentRecording() {
            if (!isEnrolling) {
                await startEnrollmentRecording();
            } else {
                await stopEnrollmentRecording();
            }
        }

        // Start enrollment recording
        async function startEnrollmentRecording() {
            const recordingIndicator = document.getElementById('recordingIndicator');
            const statusEl = document.getElementById('voiceprintStatus');

            try {
                // Get microphone access
                enrollmentMediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                enrollmentAudioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                const source = enrollmentAudioContext.createMediaStreamSource(enrollmentMediaStream);
                enrollmentAnalyser = enrollmentAudioContext.createAnalyser();
                enrollmentAnalyser.fftSize = 2048;

                source.connect(enrollmentAnalyser);

                enrollmentAudioData = [];
                isEnrolling = true;
                enrollmentRecordingStartTime = Date.now();

                // Update UI
                recordingIndicator.style.display = 'block';
                document.getElementById('enrollmentBtnIcon').textContent = 'â¹ï¸';
                document.getElementById('enrollmentBtnText').textContent = 'Stop Recording';
                statusEl.textContent = 'Recording... Please read the text above clearly.';
                statusEl.style.color = 'white';

                // Start timer
                enrollmentRecordingTimer = setInterval(() => {
                    const elapsed = Math.floor((Date.now() - enrollmentRecordingStartTime) / 1000);
                    const minutes = Math.floor(elapsed / 60);
                    const seconds = elapsed % 60;
                    document.getElementById('enrollmentTimer').textContent =
                        `${minutes}:${seconds.toString().padStart(2, '0')}`;

                    // Capture audio data
                    const dataArray = new Float32Array(enrollmentAnalyser.fftSize);
                    enrollmentAnalyser.getFloatTimeDomainData(dataArray);
                    enrollmentAudioData.push(...Array.from(dataArray));
                }, 100);

            } catch (error) {
                console.error('Enrollment failed:', error);
                statusEl.textContent = 'Failed to access microphone. Please try again.';
                statusEl.style.color = '#ff3b30';
            }
        }

        // Stop enrollment recording
        async function stopEnrollmentRecording() {
            if (!isEnrolling) return;

            const recordingIndicator = document.getElementById('recordingIndicator');
            const statusEl = document.getElementById('voiceprintStatus');

            // Stop recording
            isEnrolling = false;
            clearInterval(enrollmentRecordingTimer);

            if (enrollmentMediaStream) {
                enrollmentMediaStream.getTracks().forEach(track => track.stop());
            }
            if (enrollmentAudioContext) {
                enrollmentAudioContext.close();
            }

            // Update UI
            recordingIndicator.style.display = 'none';
            document.getElementById('enrollmentBtnIcon').textContent = 'âºï¸';
            document.getElementById('enrollmentBtnText').textContent = 'Start Recording';
            document.getElementById('enrollmentTimer').textContent = '0:00';

            // Check recording duration
            const recordingDuration = (Date.now() - enrollmentRecordingStartTime) / 1000;
            if (recordingDuration < 3) {
                statusEl.textContent = 'Recording too short. Please record at least 3 seconds.';
                statusEl.style.color = '#ff3b30';
                return;
            }

            // Extract and save features
            try {
                statusEl.textContent = 'Processing...';
                statusEl.style.color = 'white';

                const features = extractAudioFeatures(enrollmentAudioData);

                if (features && features.length > 0) {
                    const success = await saveVoiceprint(features);

                    if (success) {
                        statusEl.textContent = 'Voice registered successfully!';
                        statusEl.style.color = '#34d399';

                        setTimeout(() => {
                            hideVoiceprintModal();
                        }, 2000);
                    } else {
                        throw new Error('Failed to save voiceprint to server');
                    }
                } else {
                    throw new Error('Failed to extract voice features');
                }
            } catch (error) {
                console.error('Failed to process voiceprint:', error);
                statusEl.textContent = 'Failed to save. Please try again.';
                statusEl.style.color = '#ff3b30';
            }
        }

        // Skip voiceprint enrollment
        function skipVoiceprintEnrollment() {
            hideVoiceprintModal();
        }

        // Hide voiceprint modal
        function hideVoiceprintModal() {
            const modal = document.getElementById('voiceprintModal');
            modal.classList.remove('show');
        }

        // Check if voiceprint enrollment is needed
        async function checkVoiceprintEnrollment() {
            if (CONFIG.enableVoiceprint) {
                const hasVoiceprint = await loadVoiceprint();
                if (!hasVoiceprint) {
                    showVoiceprintModal();
                }
            }
        }

        // Update voiceprint indicator UI
        function updateVoiceprintIndicator() {
            const icon = document.getElementById('voiceprintIcon');
            const text = document.getElementById('voiceprintText');
            const indicator = document.getElementById('voiceprintIndicator');

            if (!CONFIG.callMode) {
                icon.classList.add('disabled');
                text.textContent = 'No Mode';
                indicator.title = 'Click to select call mode';
            } else if (CONFIG.callMode === 'earpiece') {
                icon.classList.remove('disabled');
                text.textContent = 'ğŸ“± Earpiece';
                indicator.title = 'Earpiece mode - Click to change';
            } else if (CONFIG.callMode === 'speaker') {
                if (CONFIG.enableVoiceprint) {
                    if (voiceprintProfile) {
                        icon.classList.remove('disabled');
                        text.textContent = 'ğŸ”Š Protected';
                        indicator.title = 'Speaker + Voiceprint - Click to change';
                    } else {
                        icon.classList.add('disabled');
                        text.textContent = 'ğŸ”Š Not Enrolled';
                        indicator.title = 'Click to register voiceprint';
                    }
                } else {
                    icon.classList.remove('disabled');
                    text.textContent = 'ğŸ”Š Speaker';
                    indicator.title = 'Speaker mode - Click to change';
                }
            }
        }

        // Open settings (mode selection or voiceprint)
        function openSettings() {
            if (!CONFIG.callMode) {
                showModeModal();
            } else if (CONFIG.callMode === 'speaker' && CONFIG.enableVoiceprint && !voiceprintProfile) {
                // å…æ+å£°çº¹ä½†æœªæ³¨å†Œï¼šæ˜¾ç¤ºå£°çº¹æ³¨å†Œ
                showVoiceprintModal();
            } else {
                // å…¶ä»–æƒ…å†µï¼šé‡æ–°é€‰æ‹©æ¨¡å¼
                showModeModal();
            }
        }

        // ========================================
        // CALL MODE SELECTION
        // ========================================

        let selectedMode = null;

        function showModeModal() {
            const modal = document.getElementById('modeModal');
            modal.classList.add('show');
        }

        function hideModeModal() {
            const modal = document.getElementById('modeModal');
            modal.classList.remove('show');
        }

        function selectMode(mode) {
            selectedMode = mode;

            // Update UI
            document.getElementById('earpieceMode').classList.remove('selected');
            document.getElementById('speakerMode').classList.remove('selected');

            if (mode === 'earpiece') {
                document.getElementById('earpieceMode').classList.add('selected');
                document.getElementById('modeWarning').style.display = 'none';
                // å¬ç­’æ¨¡å¼ç¦ç”¨å¤é€‰æ¡†
                document.getElementById('enableVoiceprintCheck').disabled = true;
                document.getElementById('enableVoiceprintCheck').checked = false;
            } else if (mode === 'speaker') {
                document.getElementById('speakerMode').classList.add('selected');
                // å…ææ¨¡å¼å¯ç”¨å¤é€‰æ¡†
                document.getElementById('enableVoiceprintCheck').disabled = false;
                updateModeWarning();
            }
        }

        function updateModeWarning() {
            const voiceprintEnabled = document.getElementById('enableVoiceprintCheck').checked;
            const warning = document.getElementById('modeWarning');

            if (selectedMode === 'speaker' && !voiceprintEnabled) {
                warning.style.display = 'block';
            } else {
                warning.style.display = 'none';
            }
        }

        // ç›‘å¬å¤é€‰æ¡†å˜åŒ–
        document.addEventListener('DOMContentLoaded', () => {
            const checkbox = document.getElementById('enableVoiceprintCheck');
            if (checkbox) {
                checkbox.addEventListener('change', updateModeWarning);
            }
        });

        async function confirmMode() {
            if (!selectedMode) {
                alert('Please select a call mode');
                return;
            }

            const voiceprintCheckbox = document.getElementById('enableVoiceprintCheck');

            // æ ¹æ®é€‰æ‹©é…ç½®CONFIG
            CONFIG.callMode = selectedMode;

            if (selectedMode === 'earpiece') {
                // å¬ç­’æ¨¡å¼ï¼šä¸éœ€è¦å£°çº¹è¯†åˆ«
                CONFIG.enableVoiceprint = false;
                console.log('Earpiece mode selected - voiceprint disabled');

            } else if (selectedMode === 'speaker') {
                // å…ææ¨¡å¼ï¼šæ ¹æ®ç”¨æˆ·é€‰æ‹©
                CONFIG.enableVoiceprint = voiceprintCheckbox.checked;
                console.log(`Speaker mode selected - voiceprint ${CONFIG.enableVoiceprint ? 'enabled' : 'disabled'}`);
            }

            // ä¿å­˜åˆ°æœåŠ¡å™¨
            try {
                const response = await fetch('/auth/user/call-mode', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        call_mode: selectedMode,
                        voiceprint_enabled: CONFIG.enableVoiceprint
                    })
                });

                if (response.ok) {
                    console.log('Call mode saved to server');
                } else {
                    console.error('Failed to save call mode to server');
                }
            } catch (e) {
                console.error('Failed to save call mode:', e);
            }

            hideModeModal();

            // å¦‚æœå¯ç”¨å£°çº¹ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ³¨å†Œ
            if (CONFIG.enableVoiceprint) {
                await checkVoiceprintEnrollment();
            }

            updateVoiceprintIndicator();
        }

        async function loadSavedMode() {
            try {
                const response = await fetch('/auth/user/voiceprint');
                if (!response.ok) {
                    console.error('Failed to load user settings from server');
                    return false;
                }

                const data = await response.json();
                if (data.call_mode) {
                    CONFIG.callMode = data.call_mode;
                    CONFIG.enableVoiceprint = data.voiceprint_enabled || false;
                    console.log(`Loaded saved mode from server: ${data.call_mode}, voiceprint: ${CONFIG.enableVoiceprint}`);
                    return true;
                }
            } catch (e) {
                console.error('Failed to load saved mode:', e);
            }

            return false;
        }

        // ========================================
        // END CALL MODE SELECTION
        // ========================================

        // Initialize on page load
        window.addEventListener('DOMContentLoaded', async () => {
            // æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„æ¨¡å¼è®¾ç½®
            const hasSavedMode = await loadSavedMode();

            if (!hasSavedMode) {
                // é¦–æ¬¡è®¿é—®ï¼Œæ˜¾ç¤ºæ¨¡å¼é€‰æ‹©
                showModeModal();
            } else {
                // å·²æœ‰è®¾ç½®ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å£°çº¹æ³¨å†Œ
                if (CONFIG.enableVoiceprint) {
                    await checkVoiceprintEnrollment();
                }
            }

            updateVoiceprintIndicator();

            // Load user info for voiceprint warnings
            loadUserInfo();
        });

        // Load user information
        async function loadUserInfo() {
            try {
                const response = await fetch('/auth/user/info');
                if (response.ok) {
                    const user = await response.json();
                    currentUserName = user.name || 'User';
                    console.log(`User name loaded: ${currentUserName}`);
                }
            } catch (e) {
                console.error('Failed to load user info:', e);
            }
        }

        // Trigger AI warning when voiceprint verification fails
        function triggerVoiceprintWarning() {
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                return;
            }

            console.log('Triggering voiceprint warning to AI');

            // Send a system message to AI
            ws.send(JSON.stringify({
                type: 'conversation.item.create',
                item: {
                    type: 'message',
                    role: 'user',
                    content: [
                        {
                            type: 'input_text',
                            text: `[System: Unrecognized voice detected. Please say: "Sorry, this doesn't seem to be ${currentUserName}'s voice. Please wait a moment."]`
                        }
                    ]
                }
            }));

            // Trigger AI response
            ws.send(JSON.stringify({ type: 'response.create' }));
        }

        // ========================================
        // END VOICEPRINT FUNCTIONS
        // ========================================

        function addMessage(role, text) {
            const msg = document.createElement('div');
            msg.className = `message ${role}`;
            msg.textContent = text;
            transcriptEl.appendChild(msg);
            transcriptEl.scrollTop = transcriptEl.scrollHeight;
        }

        function updateStatus(text, isPulse = false) {
            callStatus.textContent = text;
            if (isPulse) {
                avatar.classList.add('pulse');
            } else {
                avatar.classList.remove('pulse');
            }
        }

        async function playAudioChunk(base64Audio) {
            if (!audioContext) return;

            try {
                // è§£ç base64éŸ³é¢‘
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // è½¬æ¢ä¸ºAudioBuffer (PCM16, 24kHz, mono)
                const int16Array = new Int16Array(bytes.buffer);
                const float32Array = new Float32Array(int16Array.length);
                for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768.0;
                }

                const audioBuffer = audioContext.createBuffer(1, float32Array.length, 24000);
                audioBuffer.getChannelData(0).set(float32Array);

                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                // è®¡ç®—æ­£ç¡®çš„æ’­æ”¾æ—¶é—´ï¼Œç¡®ä¿éŸ³é¢‘å—è¿ç»­æ’­æ”¾ä¸é‡å 
                const currentTime = audioContext.currentTime;
                const startTime = Math.max(currentTime, nextPlayTime);

                source.start(startTime);

                // æ›´æ–°ä¸‹ä¸€ä¸ªéŸ³é¢‘å—åº”è¯¥å¼€å§‹çš„æ—¶é—´
                nextPlayTime = startTime + audioBuffer.duration;
            } catch (err) {
                console.error('æ’­æ”¾éŸ³é¢‘å¤±è´¥:', err);
            }
        }

        async function connect() {
            // æ£€æŸ¥æ˜¯å¦å·²é€‰æ‹©é€šè¯æ¨¡å¼
            if (!CONFIG.callMode) {
                showModeModal();
                return;
            }

            // å¦‚æœå¯ç”¨å£°çº¹ä½†æœªæ³¨å†Œï¼Œæ˜¾ç¤ºæ³¨å†Œæ¨¡æ€æ¡†
            if (CONFIG.enableVoiceprint && !voiceprintProfile) {
                showVoiceprintModal();
                return;
            }

            try {
                connectBtn.disabled = true;
                updateStatus('Connecting...', false);

                // è·å–APIå¯†é’¥
                const keyResponse = await fetch('/api_key');
                const keyData = await keyResponse.json();
                const apiKey = keyData.api_key;

                addMessage('system', 'æ­£åœ¨è¿æ¥åˆ°OpenAI Realtime API...');

                // è¿æ¥WebSocket (æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼)
                ws = new WebSocket(
                    `wss://api.openai.com/v1/realtime?model=${CONFIG.model}`,
                    [
                        'realtime',
                        'openai-insecure-api-key.' + apiKey,
                        'openai-beta.realtime-v1'
                    ]
                );

                ws.onopen = async () => {

                    // é…ç½®ä¼šè¯
                    ws.send(JSON.stringify({
                        type: 'session.update',
                        session: {
                            modalities: ['text', 'audio'],
                            instructions: 'You are a friendly AI voice assistant. You can help users find the websites and information they need through voice. When users ask questions or want to query information, you should: 1. Understand user intent 2. Use the recognize_intent tool to identify the most suitable website 3. Naturally tell users the results, including recommended website URLs. Keep conversations natural, friendly, and efficient.',
                            voice: CONFIG.voice,
                            input_audio_format: 'pcm16',
                            output_audio_format: 'pcm16',
                            input_audio_transcription: {
                                model: 'whisper-1'
                            },
                            turn_detection: {
                                type: 'server_vad',
                                threshold: CONFIG.vadThreshold,
                                prefix_padding_ms: 300,
                                silence_duration_ms: CONFIG.vadSilenceDuration
                            },
                            tools: [
                                {
                                    type: 'function',
                                    name: 'recognize_intent',
                                    description: 'è¯†åˆ«ç”¨æˆ·æŸ¥è¯¢æ„å›¾å¹¶è¿”å›æœ€åˆé€‚çš„ç½‘ç«™URLã€‚å½“ç”¨æˆ·è¯¢é—®è¦æŸ¥è¯¢æŸäº›ä¿¡æ¯ã€è®¿é—®æŸä¸ªç½‘ç«™ã€æˆ–å¯»æ‰¾æŸç±»æœåŠ¡æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·ã€‚',
                                    parameters: {
                                        type: 'object',
                                        properties: {
                                            query: {
                                                type: 'string',
                                                description: 'ç”¨æˆ·çš„æŸ¥è¯¢æ–‡æœ¬ï¼Œä¾‹å¦‚\'Pythonæ•™ç¨‹\'ã€\'è´µå·èŒ…å°è‚¡ç¥¨\'ã€\'ä¸ªäººæ‰€å¾—ç¨è®¡ç®—\'ç­‰'
                                            },
                                            top_k: {
                                                type: 'integer',
                                                description: 'è¿”å›top-kä¸ªå¯èƒ½çš„ç»“æœï¼Œé»˜è®¤3',
                                                default: 3
                                            }
                                        },
                                        required: ['query']
                                    }
                                }
                            ],
                            tool_choice: 'auto'
                        }
                    }));

                    // è·å–éº¦å…‹é£
                    try {
                        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                        // è®¾ç½®éŸ³é¢‘ä¸Šä¸‹æ–‡ (24kHzé‡‡æ ·ç‡)
                        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                        const source = audioContext.createMediaStreamSource(mediaStream);
                        const processor = audioContext.createScriptProcessor(2048, 1, 1);

                        source.connect(processor);
                        processor.connect(audioContext.destination);

                        let lastVerificationTime = 0;
                        let voiceprintVerified = !CONFIG.enableVoiceprint;  // Auto-pass if disabled
                        let voiceprintCooldownUntil = 0;  // Timestamp until which audio is blocked

                        processor.onaudioprocess = (e) => {
                            if (ws && ws.readyState === WebSocket.OPEN) {
                                const inputData = e.inputBuffer.getChannelData(0);

                                // Check if we're in cooldown period
                                const now = Date.now();
                                if (now < voiceprintCooldownUntil) {
                                    // Still in cooldown - don't send audio
                                    return;
                                }

                                // Add to realtime buffer for voiceprint verification
                                realtimeAudioBuffer.push(...Array.from(inputData));

                                // Periodic voiceprint verification
                                if (CONFIG.enableVoiceprint && (now - lastVerificationTime) >= VERIFICATION_INTERVAL) {
                                    lastVerificationTime = now;

                                    if (realtimeAudioBuffer.length >= BUFFER_SIZE) {
                                        // Verify voiceprint
                                        const bufferToVerify = realtimeAudioBuffer.slice(-BUFFER_SIZE);
                                        voiceprintVerified = verifyVoiceprint(bufferToVerify);

                                        if (!voiceprintVerified) {
                                            console.warn('Voice verification failed - entering cooldown period');

                                            // Set cooldown period
                                            voiceprintCooldownUntil = now + CONFIG.voiceprintCooldownPeriod;

                                            // Clear buffer to prevent sending unverified audio
                                            realtimeAudioBuffer = [];

                                            // Trigger AI response
                                            triggerVoiceprintWarning();

                                            return;
                                        }
                                    }
                                }

                                // Keep buffer size manageable
                                if (realtimeAudioBuffer.length > BUFFER_SIZE * 2) {
                                    realtimeAudioBuffer = realtimeAudioBuffer.slice(-BUFFER_SIZE);
                                }

                                // Only send audio if voiceprint is verified (or disabled)
                                if (voiceprintVerified || !CONFIG.enableVoiceprint) {
                                    const pcm16 = new Int16Array(inputData.length);
                                    for (let i = 0; i < inputData.length; i++) {
                                        pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                                    }

                                    // è½¬ä¸ºbase64å¹¶å‘é€
                                    const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                                    ws.send(JSON.stringify({
                                        type: 'input_audio_buffer.append',
                                        audio: base64
                                    }));
                                }
                            }
                        };

                        updateStatus('In call', true);
                        disconnectBtn.disabled = false;

                    } catch (err) {
                        updateStatus('Microphone permission denied', false);
                        connectBtn.disabled = false;
                    }
                };

                ws.onmessage = async (event) => {
                    const data = JSON.parse(event.data);
                    console.log('æ”¶åˆ°äº‹ä»¶:', data.type, data);

                    // å¤„ç†ç”¨æˆ·è¯´è¯è½¬å½•
                    if (data.type === 'conversation.item.input_audio_transcription.completed') {
                        addMessage('user', data.transcript);
                    }

                    // å¤„ç†AIå›å¤è½¬å½•
                    if (data.type === 'response.audio_transcript.done') {
                        addMessage('assistant', data.transcript);
                    }

                    // å¤„ç†AIéŸ³é¢‘è¾“å‡º
                    if (data.type === 'response.audio.delta' && data.delta) {
                        await playAudioChunk(data.delta);
                    }

                    // å¤„ç†å‡½æ•°è°ƒç”¨
                    if (data.type === 'response.function_call_arguments.done') {

                        if (data.name === 'recognize_intent') {
                            try {
                                const args = JSON.parse(data.arguments);
                                const result = await fetch('/recognize_intent', {
                                    method: 'POST',
                                    headers: { 'Content-Type': 'application/json' },
                                    body: JSON.stringify(args)
                                });
                                const resultData = await result.json();

                                // å‘é€å·¥å…·ç»“æœ
                                ws.send(JSON.stringify({
                                    type: 'conversation.item.create',
                                    item: {
                                        type: 'function_call_output',
                                        call_id: data.call_id,
                                        output: JSON.stringify(resultData, null, 2)
                                    }
                                }));

                                // è§¦å‘å“åº”
                                ws.send(JSON.stringify({ type: 'response.create' }));

                                // ä¿å­˜åˆ°å†å²è®°å½•
                                const categories = resultData.predictions?.map(p => p.category).join('ã€') || 'N/A';
                                addMessage('system', `æ¨è: ${categories}`);
                            } catch (err) {
                                console.error('å·¥å…·è°ƒç”¨å¤±è´¥:', err);
                            }
                        }
                    }

                    // å¤„ç†é”™è¯¯
                    if (data.type === 'error') {
                        console.error('æœåŠ¡å™¨é”™è¯¯:', data.error);
                    }
                };

                ws.onerror = (error) => {
                    console.error('WebSocketé”™è¯¯:', error);
                    updateStatus('Connection error', false);
                };

                ws.onclose = () => {
                    updateStatus('Click to start conversation', false);
                    connectBtn.disabled = false;
                    disconnectBtn.disabled = true;

                    if (mediaStream) {
                        mediaStream.getTracks().forEach(track => track.stop());
                    }
                    if (audioContext) {
                        audioContext.close();
                    }
                };

            } catch (error) {
                console.error('è¿æ¥é”™è¯¯:', error);
                updateStatus('Connection failed', false);
                connectBtn.disabled = false;
            }
        }

        function disconnect() {
            if (ws) {
                ws.close();
                ws = null;
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            // é‡ç½®éŸ³é¢‘æ’­æ”¾æ—¶é—´
            nextPlayTime = 0;
            // æ¸…ç©ºå£°çº¹ç¼“å†²åŒº
            realtimeAudioBuffer = [];
            updateStatus('Click to start conversation', false);
            connectBtn.disabled = false;
            disconnectBtn.disabled = true;
        }

        connectBtn.addEventListener('click', connect);
        disconnectBtn.addEventListener('click', disconnect);
    </script>
</body>
</html>
